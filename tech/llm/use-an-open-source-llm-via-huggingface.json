{
    "id": "4Nk0fnan0JC9YFS2",
    "meta": {
      "instanceId": "03524270bab2c2dfd5b82778cd1355e56cdda3cf098bf2dfd865e18164c00485"
    },
    "name": "Mistral open-source LLM example",
    "tags": [],
    "nodes": [
      {
        "id": "87ca4479-7433-44d1-95ff-3cf8c13d011e",
        "name": "On new manual Chat Message",
        "type": "@n8n/n8n-nodes-langchain.manualChatTrigger",
        "position": [
          760,
          360
        ],
        "parameters": {},
        "typeVersion": 1
      },
      {
        "id": "4a60cb10-c5d8-4850-941b-ecdd07cd32f1",
        "name": "Basic LLM Chain",
        "type": "@n8n/n8n-nodes-langchain.chainLlm",
        "position": [
          980,
          360
        ],
        "parameters": {
          "prompt": "=You are a helpful assistant. Please reply politely to the users.\nUse emojis and a text.\nQ: {{ $json.input }}\nA: "
        },
        "typeVersion": 1
      },
      {
        "id": "a32c19bf-0f0e-4c9f-99ba-79836f10e899",
        "name": "Hugging Face Inference Model",
        "type": "@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference",
        "position": [
          1000,
          560
        ],
        "parameters": {
          "model": "mistralai/Mistral-7B-Instruct-v0.1",
          "options": {
            "maxTokens": 512,
            "temperature": 0.8,
            "frequencyPenalty": 2
          }
        },
        "credentials": {
          "huggingFaceApi": {
            "id": "FPEdrzelyhrERF11",
            "name": "HuggingFaceApi account"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "157d6fc5-1523-43fc-937e-92c67b1f3991",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          480,
          20
        ],
        "parameters": {
          "width": 1083,
          "height": 317,
          "content": "## This is an example of basic LLM Chain connected to an open-source model\n### The Chain is connected to the Mistral-7B-Instruct-v0.1 model, but you can change this\n\nPlease note the initial prompt that guides the model:\n```\nYou are a helpful assistant.\nPlease reply politely to the users.\nUse emojis and a text.\nQ: {{ $json.input }}\nA: \n```\n\nThis way the model \"knows\" that it needs to answer the question right after the `A: `.\n\nSince Hugging Face node is this is an inference mode, it does not support LangChain Agents at the moment. Please use [Ollama Chat Model](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/) node for that"
        },
        "typeVersion": 1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "98c81ea4-fae0-4d6f-9a6f-6096f69c1cab",
    "connections": {
      "On new manual Chat Message": {
        "main": [
          [
            {
              "node": "Basic LLM Chain",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Hugging Face Inference Model": {
        "ai_languageModel": [
          [
            {
              "node": "Basic LLM Chain",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      }
    }
  }